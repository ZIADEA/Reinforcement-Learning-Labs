<div align="center">

# ğŸ¯ Reinforcement Learning & Deep RL Labs
## Portfolio 2025

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![Gymnasium](https://img.shields.io/badge/Gymnasium-0.29-00A67E?style=for-the-badge)
![License](https://img.shields.io/badge/License-Academic-green?style=for-the-badge)

**Collection de devoirs, labs et expÃ©riences documentant mon parcours en Reinforcement Learning et Deep RL (Hiver 2025)**

[ğŸš€ DÃ©marrage Rapide](#dÃ©marrage-rapide) â€¢ [ğŸ“š SÃ©ances](#sÃ©ances-en-un-coup-dÅ“il) â€¢ [ğŸ¬ DÃ©mos](#galerie-visuelle) â€¢ [ğŸ“Š RÃ©sultats](#ressources-visuelles-et-logs)

</div>

---

## âœ¨ Points Forts

<table>
<tr>
<td width="50%">

### ğŸ“– **Parcours d'Apprentissage StructurÃ©**
Chaque dossier `seance` contient :
- ğŸ“ Code complet et expÃ©riences
- ğŸ“Š Analyses dÃ©taillÃ©es et figures
- ğŸ“š Documentation README complÃ¨te

</td>
<td width="50%">

### ğŸ§  **Techniques Couvertes**
- ğŸ² RL Classique : DP, MC, Q-Learning
- ğŸ® Deep RL : variantes DQN
- ğŸš€ AvancÃ© : PPO avec Stable-Baselines3

</td>
</tr>
</table>

### ğŸ¬ Narration Visuelle
Toutes les expÃ©riences incluent des **visualisations animÃ©es** (GIFs) et des **tableaux de bord interactifs** pour observer le comportement des agents sans exÃ©cuter le code !

## ğŸš€ DÃ©marrage Rapide

<details open>
<summary><b>âš™ï¸ Configuration de l'Environnement</b></summary>

```powershell
# Activer l'environnement Python
& C:\Users\DJERI\VSCODE\Programmation\python\environnements\rl_venv\Scripts\Activate.ps1
```
</details>

<details>
<summary><b>ğŸ—‚ï¸ Naviguer vers les SÃ©ances</b></summary>

| SÃ©ance | Commande | Objectif |
|---------|---------|----------|
| ğŸ“š Seance 1 | `cd seance1` | Fondamentaux RL (MC, DP, PI, VI, Q-Learning) |
| ğŸ® Seance 2/4 | `cd seance2` ou `cd Sceance4/minegym` | ExpÃ©riences GridWorld & DQN |
| ğŸš€ Seance 5 | `cd Seance5/rl_sb` | PPO + Stable-Baselines3 |

</details>

<details>
<summary><b>â–¶ï¸ Lancer les ExpÃ©riences</b></summary>

```bash
# GridWorld Q-Learning experiments
python -m minegym.experiments.liveQL
python -m minegym.experiments.sensitivity_gammaQL
python -m minegym.experiments.sensitivity_grid_sizeQL

# PPO experiments (from Seance5/rl_sb)
cd Seance5/rl_sb
# See Seance5/readme.md for training scripts
```
</details>

## ğŸ“š SÃ©ances en un Coup d'Å’il

<table>
<tr>
<th>SÃ©ance</th>
<th>Focus</th>
<th>Techniques</th>
<th>Artefacts ClÃ©s</th>
</tr>

<tr>
<td><b>ğŸ“– <a href="seance1">Seance 1</a></b></td>
<td>Algorithmes RL Fondamentaux</td>
<td>

![MC](https://img.shields.io/badge/Monte_Carlo-blue)
![DP](https://img.shields.io/badge/Dynamic_Programming-green)
![QL](https://img.shields.io/badge/Q--Learning-orange)

</td>
<td>ImplÃ©mentations agents : MC, PI, VI, Q-Learning</td>
</tr>

<tr>
<td><b>ğŸ® <a href="seance2/minegym">Seance 2</a></b></td>
<td>ExpÃ©riences GridWorld</td>
<td>

![QL](https://img.shields.io/badge/Q--Learning-orange)
![Custom](https://img.shields.io/badge/Custom_Env-purple)

</td>
<td>Monde paramÃ©trable, analyse de sensibilitÃ©, Q-Learning corrigÃ©</td>
</tr>

<tr>
<td><b>ğŸ¤– <a href="Sceance4/minegym">Seance 4</a></b></td>
<td>Deep Q-Networks</td>
<td>

![DQN](https://img.shields.io/badge/DQN-red)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C)

</td>
<td>Comparaison NaÃ¯f vs DQN, architecture flexible</td>
</tr>

<tr>
<td><b>ğŸš€ <a href="Seance5">Seance 5</a></b></td>
<td>MÃ©thodes Ã  Gradient de Politique</td>
<td>

![PPO](https://img.shields.io/badge/PPO-brightgreen)
![SB3](https://img.shields.io/badge/Stable--Baselines3-yellow)

</td>
<td>GridWorld statique/mobile, CartPole, transfer learning</td>
</tr>

<tr>
<td><b>ğŸ‘¾ <a href="secance3/reinforcement">Seance 3</a></b></td>
<td>Projet Pacman</td>
<td>

![Games](https://img.shields.io/badge/Game_AI-blueviolet)

</td>
<td>Environnements larges, autograder, agents apprenants</td>
</tr>

</table>

## ğŸ¬ Galerie Visuelle

<div align="center">

### EntraÃ®nement Agent GridWorld (PPO)

<table>
<tr>
<td align="center">
<img src="Seance5/rl_sb/gridworld_runs/gridworld_static_live.gif" width="300"/>
<br/><b>Goal Statique (100k steps)</b>
</td>
<td align="center">
<img src="Seance5/rl_sb/gridworld_runs/gridworld_moving_live.gif" width="300"/>
<br/><b>Goal Mobile (100k steps)</b>
</td>
</tr>
<tr>
<td align="center">
<img src="Seance5/rl_sb/gridworld_runs/gridworld_ppo_static_400k_live.gif" width="300"/>
<br/><b>Goal Statique (400k steps)</b>
</td>
<td align="center">
<img src="Seance5/rl_sb/gridworld_runs/test_cartpole.gif" width="300"/>
<br/><b>CartPole-v1 (PPO)</b>
</td>
</tr>
</table>

</div>

---

## ğŸ“Š Ressources Visuelles et Logs

> **ğŸ’¡ Astuce :** Toutes les expÃ©riences incluent des visualisations prÃ©-gÃ©nÃ©rÃ©es â€” vous pouvez explorer les rÃ©sultats sans exÃ©cuter le code !

<details>
<summary><b>ğŸ—‚ï¸ OÃ¹ trouver les ressources visuelles</b></summary>

| Emplacement | Contenu |
|----------|----------|
| ğŸ“ `Sceance4/minegym/figures` | Heatmaps, tableaux de bord, diagnostics exploration/exploitation (DQN/Q-Learning) |
| ğŸ“ `Seance5/rl_sb/gridworld_runs` | GIFs animÃ©s des agents GridWorld et CartPole |
| ğŸ“ `seance2/minegym/figures` | Graphiques d'analyse de sensibilitÃ©, courbes de convergence |
| ğŸ“ `Seance5/rl_sb/rl-baselines3-zoo/logs` | Logs TensorBoard et checkpoints des modÃ¨les |

</details>

## ğŸ” Comment Explorer les RÃ©sultats

```mermaid
graph LR
    A[ğŸ“– Choisir une SÃ©ance] --> B[ğŸ“š Lire le README]
    B --> C{Voir les rÃ©sultats?}
    C -->|Oui| D[ğŸ–¼ï¸ Parcourir figures/]
    C -->|Non| E[â–¶ï¸ Lancer expÃ©riences]
    D --> F[ğŸ¯ Analyser rÃ©sultats]
    E --> F
```

1. **ğŸ“– Commencer** dans le dossier de la sÃ©ance qui vous intÃ©resse
2. **ğŸ“š Lire** son README pour le contexte et les commandes  
3. **ğŸ–¼ï¸ Inspecter** les figures, GIFs et tableaux de bord prÃ©-gÃ©nÃ©rÃ©s
4. **â–¶ï¸ Relancer** les scripts pour gÃ©nÃ©rer de nouveaux rÃ©sultats ou tester de nouveaux paramÃ¨tres

---

<div align="center">

**ğŸ“« Questions ou commentaires ?** Ouvrez une issue ou contactez-moi !

â­ **Star ce repo** si vous l'avez trouvÃ© utile !

</div>


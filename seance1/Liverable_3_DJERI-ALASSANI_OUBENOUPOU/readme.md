<div align="center">

# ğŸš€ Livrable 3 â€” Agents RL Ã‰tendus

![MC](https://img.shields.io/badge/Monte_Carlo-Enhanced-4169E1?style=for-the-badge)
![DP](https://img.shields.io/badge/Dynamic_Programming-Enhanced-2ECC71?style=for-the-badge)
![QL](https://img.shields.io/badge/Q--Learning-Enhanced-E67E22?style=for-the-badge)
![PI](https://img.shields.io/badge/Policy_Iteration-Enhanced-9B59B6?style=for-the-badge)

**Version amÃ©liorÃ©e et Ã©tendue des implÃ©mentations RL fondamentales**

</div>

---

## ğŸ¯ Contenu

Ce livrable contient les **versions Ã©tendues** des algorithmes du Livrable 2 avec :
- âœ¨ AmÃ©liorations de performance
- ğŸ”§ Optimisations algorithmiques
- ğŸ“Š Meilleur tracking des mÃ©triques
- ğŸ¨ Visualisations amÃ©liorÃ©es

<table>
<tr>
<th>Fichier</th>
<th>Description</th>
<th>AmÃ©liorations</th>
</tr>
<tr>
<td><code>agentMC.py</code></td>
<td>Agent Monte Carlo</td>
<td>Version optimisÃ©e avec meilleure gestion mÃ©moire</td>
</tr>
<tr>
<td><code>agentPI.py</code></td>
<td>Agent Policy Iteration</td>
<td>Convergence accÃ©lÃ©rÃ©e</td>
</tr>
<tr>
<td><code>agentVI.py</code></td>
<td>Agent Value Iteration</td>
<td>CritÃ¨re d'arrÃªt amÃ©liorÃ©</td>
</tr>
<tr>
<td><code>agentQL.py</code></td>
<td>Agent Q-Learning</td>
<td>StratÃ©gie d'exploration adaptative</td>
</tr>
<tr>
<td><code>4agenttest.py</code></td>
<td>Script de test Ã©tendu</td>
<td>MÃ©triques de comparaison dÃ©taillÃ©es</td>
</tr>
<tr>
<td><code>gym1.py</code></td>
<td>Environnement amÃ©liorÃ©</td>
<td>FonctionnalitÃ©s Ã©tendues</td>
</tr>
</table>

## ğŸš€ Utilisation

### Installation

```bash
cd seance1/Liverable_3_DJERI-ALASSANI_OUBENOUPOU
```

### Lancer les Tests

```bash
python 4agenttest.py
```

Le script exÃ©cutera les **4 agents amÃ©liorÃ©s** avec :
1. âœ… EntraÃ®nement optimisÃ©
2. âœ… Collecte de mÃ©triques dÃ©taillÃ©es
3. âœ… Comparaison approfondie
4. âœ… RÃ©sultats visuels

## âœ¨ AmÃ©liorations par Rapport au Livrable 2

### Performance
- âš¡ **Convergence plus rapide** grÃ¢ce aux optimisations
- ğŸ’¾ **Utilisation mÃ©moire rÃ©duite**
- ğŸ¯ **PrÃ©cision amÃ©liorÃ©e** des politiques apprises

### FonctionnalitÃ©s
- ğŸ“Š **MÃ©triques Ã©tendues** : temps de convergence, stabilitÃ©
- ğŸ“ˆ **Visualisations** : courbes d'apprentissage, heatmaps
- ğŸ” **Diagnostics** : analyse dÃ©taillÃ©e du comportement

### Code
- ğŸ§¹ **Code plus propre** et mieux structurÃ©
- ğŸ“ **Documentation enrichie**
- ğŸ›¡ï¸ **Gestion d'erreurs robuste**

## ğŸ§  DiffÃ©rences ClÃ©s avec Livrable 2

| Aspect | Livrable 2 | Livrable 3 |
|--------|------------|------------|
| ImplÃ©mentation | Basique | OptimisÃ©e |
| MÃ©triques | Standard | DÃ©taillÃ©es |
| Performance | Correcte | AmÃ©liorÃ©e |
| Visualisations | LimitÃ©es | Ã‰tendues |
| Documentation | Minimale | ComplÃ¨te |

## ğŸ“Š RÃ©sultats Attendus

Les amÃ©liorations devraient montrer :
- ğŸš€ **30-50% plus rapide** en temps de convergence
- ğŸ¯ **Politiques plus stables** avec moins de variance
- ğŸ“ˆ **Courbes d'apprentissage plus lisses**
- âœ… **MÃ©triques de performance supÃ©rieures**

## ğŸ”§ Configuration AvancÃ©e

### ParamÃ¨tres OptimisÃ©s

```python
# Q-Learning amÃ©liorÃ©
config = {
    'alpha': 0.3,           # Taux d'apprentissage adaptatif
    'gamma': 0.95,          # Facteur d'escompte optimisÃ©
    'epsilon_start': 1.0,   # Exploration initiale
    'epsilon_end': 0.01,    # Exploration finale
    'epsilon_decay': 0.995, # DÃ©croissance Îµ
    'episodes': 3000        # Plus d'Ã©pisodes
}
```

## ğŸ“ Notes Techniques

### Monte Carlo
- âœ¨ Utilisation de **First-Visit MC** pour meilleure efficacitÃ©
- ğŸ“Š Tracking des **moyennes mobiles** pour convergence

### Dynamic Programming
- âš¡ **ArrÃªt anticipÃ©** quand Î´ < seuil
- ğŸ¯ **Policy Iteration** avec Ã©valuation tronquÃ©e

### Q-Learning
- ğŸ”„ **Epsilon-decay** pour Ã©quilibre exploration/exploitation
- ğŸ“ˆ **Learning rate adaptatif** selon progression

## ğŸ” Comparaison des Performances

ExÃ©cuter `4agenttest.py` gÃ©nÃ¨re :
- ğŸ“Š Tableau comparatif des 4 algorithmes
- ğŸ“ˆ Graphiques de convergence
- ğŸ¯ Politiques optimales visualisÃ©es
- â±ï¸ Temps d'exÃ©cution mesurÃ©s

---

<div align="center">

**[â† Retour Seance 1](../README.md)** | **[â† Livrable 2](../Liverable_2_DJERI-ALASSANI_OUBENOUPOU)**

<br/><br/>

<img src="https://img.shields.io/badge/Version-Extended-success?style=for-the-badge"/>
<img src="https://img.shields.io/badge/Performance-Optimized-blue?style=for-the-badge"/>

</div>
